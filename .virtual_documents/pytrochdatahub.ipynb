#make sure on datahub
#pytorch
    


#outline 
# 0) install pytorch and vocab 
# 1) get data 
# 2) build model
#3) train model
# 4) evaluate performance
# 5) comparee model result to actual hidden pattern
# 6) improve model 



#install pytorch
%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu


# 1) get our data 
# import data 
import data 


#lets look at our data 
import matplotlib.pyplot as plt

plt.figure(figsize=(3,3))
plt.scatter(data.x_values, data.y_values, c=data.color_values)
plt.show()


#build model 
import torch

model = torch.nn.Sequential(
    torch.nn.Linear(2,50),
    torch.nn.Sigmoid(),
    torch.nn.Linear(50,1)
)


# 3 train model 
#loss function 
loss_fn = torch.nn.MSELoss()
#optimizer n
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)


#loops
#training loop
#the model will imporve each time it works thru loop
for t in range(10000):
    y_pred = model(data.x)
    loss = loss_fn(y_pred, data.y)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if t % 100 ==0:
        print(f"Iteration {t}, Loss: {loss.item()}")



# 4) eval model 
new_x = torch.linspace(-10,10,100)
grid = torch.stack(torch.meshgrid((new_x,new_x)),dim = 2)

output=model(grid).detach()
plt.imshow(output,exten(-10,10,-10,10))
plt.show()


#compare model to actual hidden pattern
plt.imshow(data.pattern)
plt.show()


#improve our model
#increase neuron count 
#add more layers
#adjust learning rate 
#train it longer (more iterations)
#not use Sigmoid, use ReLU
